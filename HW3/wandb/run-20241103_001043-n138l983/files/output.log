Traceback (most recent call last):
  File "D:\Facultate\Master\ANN\HW3\main.py", line 212, in <module>
    main()
  File "D:\Facultate\Master\ANN\HW3\main.py", line 197, in main
    train_acc = train(**context, epoch=epoch)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\HW3\main.py", line 31, in train
    for batch_index, (inputs, targets) in enumerate(train_loader):
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\utils\data\dataloader.py", line 701, in __next__
    data = self._next_data()
           ^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\utils\data\dataloader.py", line 757, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
            ~~~~~~~~~~~~^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torchvision\datasets\cifar.py", line 119, in __getitem__
    img = self.transform(img)
          ^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torchvision\transforms\v2\_container.py", line 51, in forward
    outputs = transform(*inputs)
              ^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torchvision\transforms\transforms.py", line 95, in __call__
    img = t(img)
          ^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torchvision\transforms\transforms.py", line 681, in forward
    i, j, h, w = self.get_params(img, self.size)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Facultate\Master\ANN\venv\Lib\site-packages\torchvision\transforms\transforms.py", line 640, in get_params
    raise ValueError(f"Required crop size {(th, tw)} is larger than input image size {(h, w)}")
ValueError: Required crop size (224, 224) is larger than input image size (40, 40)
